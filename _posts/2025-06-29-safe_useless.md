---
layout: post
title: "Безопасно, но бесполезно"
translated_by: К. Кирдан
excerpt: "«Этот тип безопасности подразумевает бесполезность» (или, наоборот, «любой ИИ, достаточно мощный, чтобы быть полезным, все равно будет небезопасным») — это обвинение, которое было выдвинуто против предлагаемой меры безопасности, которая для обеспечения безопасности ИИ должна применяться до такой степени, что сделает ИИ бесполезным."
original: https://arbital.com/p/safe_useless/
license: https://creativecommons.org/licenses/by/3.0/deed.ru
---
«Этот тип безопасности подразумевает бесполезность» (или, наоборот, «любой ИИ, достаточно мощный, чтобы быть полезным, все равно будет небезопасным») — это обвинение, которое было выдвинуто против предлагаемой меры безопасности, которая для обеспечения безопасности ИИ должна применяться до такой степени, что сделает ИИ бесполезным.

В качестве метафоры, не связанной с ИИ, рассмотрим ножницы и их опасные лезвия. У нас могут быть «безопасные ножницы», которые остры _лишь настолько_, чтобы разрезать бумагу, но они при этом достаточно остры, чтобы причинить некоторый вред, если над этим поработать. Если вы попытаетесь сделать ножницы _еще безопаснее_, поместив опасные лезвия в пенопласт, ножницы больше не смогут резать бумагу. Ведь если ножницы _могут_ резать бумагу, они все еще небезопасны. Возможно, в принципе вы могли бы резать такими ножницами глину, но это не аргумент, если только вы не расскажете нам, что [такого очень полезного][pivotal] можно сделать, разрезая глину.

Точно так же есть очевидный способ попытаться сократить разрешенный вывод [ОИИ-оракула][oracle] до такой степени, что [все, что он может делать, — это сообщать нам, что введенная теорема доказуема в системе аксиом теории множеств Цермело-Френкеля (ZF)][ZF_provability_oracle]. Это [может][strong_uncontainability] помешать ОИИ взломать людей-операторов и заставить их выпустить его на свободу, поскольку все, что может покинуть ящик, — это один бит со значением «да» или «нет», отправленный в определенное время. Ненадежный сверхинтеллект внутри этой схемы имел бы возможность стратегически не сообщать нам о _доказуемости_ теорем в ZF, но если бы часть средств проверки доказательств сообщала нам, что введенная теорема ZF-доказуема, мы, скорее всего, могли бы поверить им.

Но теперь мы сталкиваемся с проблемой: никто не знает, как [реально спасти мир][pivotal], просто иногда обладая надежным знанием о том, что какие-то теоремы доказуемы в ZF. Ножницы затупились до такой степени, что, вероятно, совершенно безопасны, но ими можно резать только глину. И никто не знает, как [принести _достаточно_ пользы][pivotal], разрезая глину.

## Идеальные модели «безопасных, но бесполезных» агентов

Если у вас есть причины для проведения математического исследования этого вопроса, то отличная [идеальная модель][unbounded_analysis] безопасного, но бесполезного агента, воплощающая максимальную безопасность и минимальную полезность — это булыжник.

{% include routes.html %}

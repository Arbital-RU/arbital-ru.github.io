---
layout: post
title: "Другое-зация (разыскивается: новое выражение для оптимизации)"
translated_by: К. Кирдан
translation_details: "добавлены ссылки"
excerpt: "Открытая проблема «другое-зации» [other-izing] заключается в том, чтобы найти что-то помимо максимизации, сатисфаизации, мелиоризации и нескольких других существующих, но неудовлетворительных выражений, что действительно подошло бы в качестве обозначения оптимизации, производимой ограниченными агентами и было бы рефлексивно устойчивым."
original: https://arbital.com/p/otherizer/
license: https://creativecommons.org/licenses/by/3.0/deed.ru
math: true
---
Открытая проблема «другое-зации» \[other-izing\] заключается в том, чтобы найти что-то помимо максимизации, [сатисфаизации](https://en.wikipedia.org/wiki/Satisficing), мелиоризации и нескольких других существующих, но неудовлетворительных выражений, что действительно подошло бы в качестве формулировки для оптимизации, производимой [ограниченными агентами][bounded_agent] и было бы [рефлексивно устойчивым][reflective_stability].

В стандартной теории мы склонны предполагать, что агенты являются _максимизаторами_ [ожидаемой полезности][expected_utility], которые всегда выбирают доступный вариант с наибольшей ожидаемой полезностью. Но это понятие нереалистично, потому что реалистичный, [ограниченный агент][bounded_agent] с ограниченной вычислительной мощностью не может вычислить ожидаемую полезность каждого возможного действия.

Сатисфаизатор ожидаемой полезности, который может одобрить любую политику, ожидаемая полезность которой составляет, например, по меньшей мере $0.95$, был бы гораздо более реалистичным. Но он всё ещё выглядит неподходящим для фактического ОИИ. Поскольку, например, если политика $Х$ производит по меньшей мере ожидаемую полезность $0.98$, то удовлетворительным будет также случайный выбор между политикой $X$ для большей части случаев и политикой $Y$ с нулевой ожидаемой полезностью для оставшихся случаев. Похоже, это ведёт к потере неоправданно большого количества полезности. Мы, вероятно, были бы весьма обеспокоены, если бы в остальном согласованный с нами ОИИ собирался вести себя так на самом деле.

Кроме того, сатисфаизация является [рефлексивно последовательной][reflective_consistency], но не [рефлексивно устойчивой][reflective_stability]. Хотя [теория тайлинговых агентов][tiling_agents] может дать формулировки сатисфаизаторов, которые одобрят строительство таких же сатисфаизаторов, сатисфаизаторы могут также производить максимизаторов. Если ваш критерий принятия решения заключается в утверждении политики, которая достигает ожидаемой полезности по меньшей мере $\theta$ и вы ожидаете, что соответствующий _максимизатор_ ожидаемой полезности достигнет ожидаемой полезности по меньшей мере $\theta$, то вы одобрите самомодификацию в максимизатора ожидаемой полезности. Это еще одна причина предпочесть какую-то другую формулировку для оптимизации. Потому что если ИИ сильно самомодифицируется, то нет никакой гарантии, что свойство «сатисфаизации» будет сохраняться и что наш анализ будет оставаться применимым. И даже без сильной самомодификации, он все еще может создавать не-сатисфаизирующие куски когнитивного механизма внутри себя или в окружающей среде.

Мелиоризатор имеет текущую политику и заменяет ее только политикой с более высокой ожидаемой полезностью. Опять же, можно продемонстрировать, что мелиоризатор может одобрить самомодификацию в другого мелиоризатора, так что эта формулировка рефлексивно последовательна. Но не похоже, что она будет рефлексивно устойчивой, ведь превращение в максимизатора или что-то еще может иметь более высокую ожидаемую полезность, чем оставаться мелиоризатором.

Открытая проблема «другое-зации» заключается в том, чтобы найти что-то помимо максимизации, сатисфаизации и мелиоризации, что 1) действительно имело бы смысл в качестве обозначения для оптимизации у ограниченных в ресурсах агентов, 2) было бы такой штукой, которой, как мы думаем, можно было бы заниматься, например, [ОИИ-для-поручений][task_agi], а также 3) было бы по меньшей мере рефлексивно последовательным и желательно рефлексивно устойчивым.

Дальнейший desideratum см. также в «[Умеренной оптимизации][soft_optimizer]» (а именно, в другое-заторе хорошо было бы иметь регулируемый параметр силы оптимизации).

{% include routes.html %}

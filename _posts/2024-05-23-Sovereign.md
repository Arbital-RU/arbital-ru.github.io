---
layout: post
title: Автономный ОИИ
translated_by: К. Кирдан
translation_details: "поправлены ссылки"
excerpt: "Автономный или самоуправляющийся продвинутый агент — это машинный интеллект, который действует в реальном мире в соответствии со своими предпочтениями без дальнейшего вмешательства или управления со стороны пользователя. В приведенной Бостромом типологии продвинутых агентов это «суверен», и он отличается от «джинна» и «оракула». («Суверен» тут означает «самостоятельный», не путайте с идеей бостромовского синглтона или какими-либо видами управления обществом.)"
---
Автономный или самоуправляющийся [продвинутый агент][advanced_agent] — это машинный интеллект, который действует в реальном мире в соответствии со своими предпочтениями без дальнейшего вмешательства или управления со стороны пользователя. В приведенной [Бостромом][NickBostrom] [типологии продвинутых агентов][AGI_typology] это «суверен», и он отличается от «[джинна][task_agi]» и «[оракула][oracle]». («Суверен» тут означает «самостоятельный», не путайте с идеей [бостромовского синглтона](http://www.nickbostrom.com/fut/singleton.html) или какими-либо видами управления обществом.)

Обычно, когда мы говорим «суверенный» или «самоуправляющийся», мы имеем в виду ИИ, который предполагается [согласованным][value_alignment_problem] и действует автономно _по замыслу_ создателей. Неспособность решить задачу согласования при создании ИИ, вероятно, по умолчанию будет значить, что он самоуправляющийся.

Попытка создать автономный Дружественный ИИ предполагает, что в любом конфликте между ИИ и [программистами][value_alignment_programmer] мы будем больше доверять ИИ, и мы согласны с устранением всех его ограничений и кнопок отключения, за исключением тех, которые он возьмет на себя добровольно.

_Успешно_ согласованный автономный ОИИ будет нести наименьшую [моральную угрозу][moral_hazard] по сравнению с другими сценариями, поскольку он откажется от направления к какой-либо фиксированной [системе предпочтений][preference_framework] или цели, которую программисты больше не могли бы изменить. Тем не менее, выглядит довольно трудной задачей достичь очень очень очень высокой уверенности, что мы не просто сделали все правильно, но и _знаем_, что сделали все правильно. Поэтому, возможно, нам не следует пытаться _с первой же попытки_ создать ИИ именно этого типа, а следует вместо этого сначала нацелиться на создание [ОИИ-для-поручений][task_agi] или чего-то еще, предполагающего постоянное управление со стороны пользователя.

Автономный [сверхинтеллект][superintelligent] был бы самым трудным для [согласования][value_alignment_problem] классом ОИИ, и требовал бы [полного согласования][total_alignment]. В качестве цели в согласовании автономного сверинтеллекта предложено [когерентное экстраполированное воление][cev]. Но, опять же, вероятно это не то, что нам следует пытаться сделать с первой же попытки.

{% include routes.html %}

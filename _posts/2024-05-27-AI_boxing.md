---
layout: post
title: ИИ-в-коробке
translated_by: К. Кирдан
excerpt: "Теория ИИ-в-коробке посвящена вариантам машинного интеллекта, которые, как утверждается, более безопасны из-за того, что имеют предположительно крайне ограниченные доступные для манипуляций каналы для каузального взаимодействия с внешней вселенной."
---
Теория ИИ-в-коробке посвящена вариантам машинного интеллекта, которые, как утверждается, более безопасны из-за того, что имеют предположительно крайне ограниченные доступные для манипуляций каналы для каузального взаимодействия с внешней вселенной.

Теория ИИ-в-коробке включает в себя:

- Прямую задачу создания сложных «песочниц» (компьютеров и сред моделирования, спроектированных так, чтобы не иметь каналов каузального взаимодействия с внешней вселенной, доступных для манипулирования).
- [Предвидимые трудности][foreseeable_difficulties], при которых оставшиеся ограниченные каналы взаимодействия могут быть использованы ИИ для манипулирования внешней вселенной, особенно людьми-операторами.
- Попытки разработать [системы предпочтений][preference_framework], которые не стимулируют ИИ выходить за пределы «коробки» и не стимулируют манипулировать внешней вселенной или людьми-операторами, а стимулируют четко отвечать на вопросы или выполнять любую другую деятельность, которая, как утверждается, будет выполняться внутри «коробки».

Основная трудность теории ИИ-в-коробке заключается в описании такого канала, который ИИ не мог бы использовать для манипулирования людьми-операторами, но который дает информацию, достаточно значимую, чтобы иметь [решающее или переломное значение][pivotal] по сравнению с более крупными событиями. Например, кажется вполне возможным, что [мы могли бы безопасно извлечь из установки ИИ-в-коробке надежную информацию о том, что какие-то заранее определенные теоремы были доказаны в рамках теории множеств Цермело-Френкеля][ZF_provability_oracle], но нет известного способа спасти мир, который опирался бы именно на такие знания.

{% include routes.html %}
